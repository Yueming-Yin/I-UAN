data:
  dataset:
    name: office # choices are ['office', 'officehome', 'caltech-imagenet', 'visda2017']
    root_path: /home/yinmingyue/files/Datasets/Office # /path/to/dataset/root
    source: 0 # source domain index
    target: 1 # target domain index
    n_share: 10 # number of classes to be shared
    n_source_private: 10 # number of classes in source private domain
    n_total: 31 # number of classes in total

  dataloader:
    class_balance: true # if class_balance when loading datasets
    data_workers: 3 # how many workers to use for train dataloaders
    batch_size: 36 # batch_size for source domain and target domain respectively

model:
  base_model: resnet50 # choices=['resnet50', 'vgg16']
  pretrained_model: /home/yinmingyue/.torch/models/resnet50-19c8e357.pth # /path/to/pretrained/model

train:
  min_step: 20000 # minimum steps to run. run epochs until it exceeds the minStep
  lr: 0.01 # learning rate for new layers. learning rate for finetune is 1/10 of lr
  weight_decay: 0.0005 # weight_decay for SGD optimizer
  momentum: 0.9  # momentum for SGD optimizer
  cut: 1.0  # cut threshold for normalizing weights

test:
  test_interval: 500 # interval of two continuous test phase
  test_only: True # test a given model and exit
  resume_file: ./log/A-D/best.pkl # model to test

misc:
  gpus: 1  # how many GPUs to be used, 0 indicates CPU only, needed GPU memory < 8G
  gpu_id: "7"  # which GPU you want to use
  gpu_id_list: [0] # [0,...,gpus-1]

log:
  root_dir: log # the log directory (log directory will be {root_dir}/{method}/time/)
  log_interval: 10 # steps to log scalars